# Bert-Model-for-Sentiment-Analysis
Bidirectional Encoder Representations from Transformers (BERT) is a technique for natural language processing (NLP) pre-training developed by Google. BERT was created and published in 2018 by Jacob Devlin and his colleagues from Google.

# Dataset used for training and validation.
https://www.kaggle.com/kazanova/sentiment140
